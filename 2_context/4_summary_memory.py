import boto3
import streamlit as st
from langchain_aws import ChatBedrock
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryMemory

# AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bedrock_client = boto3.client("bedrock-runtime", region_name="us-east-1")

# LangChain BedrockChat ì´ˆê¸°í™”
bedrock = ChatBedrock(
    client=bedrock_client,
    model_id="anthropic.claude-3-haiku-20240307-v1:0",
    model_kwargs={"anthropic_version": "bedrock-2023-05-31"},
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    # SummaryMemory ì´ˆê¸°í™” (í•„ìš”í•  ë•Œë§Œ ìƒì„±)
    st.session_state.memory = ConversationSummaryMemory(
        llm=bedrock,  # ìš”ì•½ì„ ìƒì„±í•  LLM
        memory_key="history",
        return_messages=True,
        max_token_limit=1000,
    )

# ConversationChain ì´ˆê¸°í™”
conversation = ConversationChain(
    llm=bedrock, memory=st.session_state.memory, verbose=True
)

# Streamlit ì•± ì„¤ì •
st.title("Chatbot Ver.2.3 : ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬ ì±—ë´‡")
st.caption("ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# í˜„ì¬ ëŒ€í™” ìš”ì•½ í‘œì‹œ
with st.sidebar:
    st.header("ğŸ’­ í˜„ì¬ ëŒ€í™” ìš”ì•½")
    current_summary = conversation.memory.load_memory_variables({})
    if current_summary["history"]:
        st.info(current_summary["history"])
    else:
        st.info("ì•„ì§ ëŒ€í™”ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    st.divider()
    st.caption("ëŒ€í™”ê°€ ì§„í–‰ë ìˆ˜ë¡ AIê°€ ìë™ìœ¼ë¡œ ì´ì „ ëŒ€í™”ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("Message Bedrock..."):
    # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # LangChain ëŒ€í™” ì²´ì¸ ì‹¤í–‰
    with st.chat_message("assistant"):
        with st.spinner("AIê°€ ë‹µë³€ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
            response = conversation.run(input=prompt)
            st.markdown(response)

    # ëª¨ë¸ ì‘ë‹µ ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": response})

# ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ì°¸ê³ ìš©)
with st.expander("ğŸ” ë””ë²„ê·¸ ì •ë³´", expanded=False):
    st.subheader("ë©”ëª¨ë¦¬ ë³€ìˆ˜")
    st.json(conversation.memory.load_memory_variables({}))

    st.subheader("ì „ì²´ ë©”ì‹œì§€ ê¸°ë¡")
    st.json(st.session_state.messages)
