import boto3
import streamlit as st
from langchain_aws import ChatBedrock
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryMemory
from langchain.prompts import PromptTemplate

# AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bedrock_client = boto3.client("bedrock-runtime", region_name="us-east-1")

# LangChain BedrockChat ì´ˆê¸°í™”
bedrock = ChatBedrock(
    client=bedrock_client,
    model_id="anthropic.claude-3-haiku-20240307-v1:0",
    model_kwargs={"anthropic_version": "bedrock-2023-05-31"},
)

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    # í•œê¸€ ìš”ì•½ì„ ê°•ì œí•˜ëŠ” í”„ë¡¬í”„íŠ¸
    summary_prompt = PromptTemplate(
        input_variables=["summary", "new_lines"],
        template="AIì™€ ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ë°˜ë“œì‹œ í•œê¸€ë¡œ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì„œ ë©”ëª¨ë¦¬ë¥¼ ìœ ì§€í•´ë¼ \n ê¸°ì¡´ ë‚´ìš© : {summary} \n ìƒˆë¡œìš´ ë‚´ìš© : {new_lines}",
    )
    # ConversationSummaryMemoryì— í•œê¸€ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì ìš©
    st.session_state.memory = ConversationSummaryMemory(
        llm=bedrock,
        memory_key="history",
        return_messages=True,
        max_token_limit=1000,
        prompt=summary_prompt,
    )

# ConversationChain ì´ˆê¸°í™”
conversation = ConversationChain(
    llm=bedrock, memory=st.session_state.memory, verbose=True
)

# Streamlit UI ì„¤ì •
st.title("Chatbot Ver.2.4 : í•œê¸€ ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬ ì±—ë´‡")
st.caption("ì´ì „ ëŒ€í™” ë‚´ìš©ì„ **í•œê¸€ë¡œ ìš”ì•½**í•˜ì—¬ ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# âœ… í˜„ì¬ ëŒ€í™” ìš”ì•½ (í•œê¸€ ì ìš©)
with st.sidebar:
    st.header("ğŸ’­ í˜„ì¬ ëŒ€í™” ìš”ì•½")
    current_summary = conversation.memory.load_memory_variables({})
    if current_summary["history"]:
        st.info(current_summary["history"])  # ğŸ”¹ ìë™ìœ¼ë¡œ í•œê¸€ ìš”ì•½ë¨
    else:
        st.info("ì•„ì§ ëŒ€í™”ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    st.divider()
    st.caption("ëŒ€í™”ê°€ ì§„í–‰ë ìˆ˜ë¡ AIê°€ ìë™ìœ¼ë¡œ ì´ì „ ëŒ€í™”ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("Message Bedrock..."):
    # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # LangChain ëŒ€í™” ì‹¤í–‰
    with st.chat_message("assistant"):
        with st.spinner("AIê°€ ë‹µë³€ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
            response = conversation.run(input=prompt)
            st.markdown(response)

    # ëª¨ë¸ ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})

# ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ì°¸ê³ ìš©)
with st.expander("ğŸ” ë””ë²„ê·¸ ì •ë³´", expanded=False):
    st.subheader("ë©”ëª¨ë¦¬ ë³€ìˆ˜")
    st.json(conversation.memory.load_memory_variables({}))

    st.subheader("ì „ì²´ ë©”ì‹œì§€ ê¸°ë¡")
    st.json(st.session_state.messages)
